{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.8.1+cu102\n",
      "  Downloading https://download.pytorch.org/whl/cu102/torch-1.8.1%2Bcu102-cp38-cp38-linux_x86_64.whl (804.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 804.1 MB 20 kB/s  eta 0:00:0143   |████████████████▍               | 411.5 MB 888 kB/s eta 0:07:22██████████████████████▌       | 616.4 MB 13.9 MB/s eta 0:00:14\n",
      "\u001b[?25hCollecting torchvision==0.9.1+cu102\n",
      "  Downloading https://download.pytorch.org/whl/cu102/torchvision-0.9.1%2Bcu102-cp38-cp38-linux_x86_64.whl (17.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3 MB 43.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchaudio===0.8.1\n",
      "  Downloading torchaudio-0.8.1-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 22.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages/numpy-1.19.2-py3.8-linux-x86_64.egg (from torch==1.8.1+cu102) (1.19.2)\n",
      "Collecting typing-extensions\n",
      "  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from torchvision==0.9.1+cu102) (8.0.1)\n",
      "Installing collected packages: typing-extensions, torch, torchvision, torchaudio\n",
      "Successfully installed torch-1.8.1+cu102 torchaudio-0.8.1 torchvision-0.9.1+cu102 typing-extensions-3.10.0.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch==1.8.1+cu102 torchvision==0.9.1+cu102 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkoGLH_Tj5wn"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ORj09gnrj5wp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23936,
     "status": "ok",
     "timestamp": 1524974497505,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "NnT0sZIwj5wu",
    "outputId": "55aed925-d17e-4c6a-8c71-0d9b3bde5637"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "# Architecture\n",
    "NUM_FEATURES = 128*128\n",
    "NUM_CLASSES = 8\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = 'cuda:0' # default GPU device\n",
    "GRAYSCALE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = './downloads500'\n",
    "all_folders = os.listdir(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## renaming images\n",
    "\n",
    "# ct = 0\n",
    "# for ii in all_folders:\n",
    "#     dd = os.path.join(img_dir, ii)\n",
    "#     allimg = os.listdir(dd)\n",
    "#     for idx, filename in enumerate(allimg):\n",
    "#         os.rename(os.path.join(dd,filename), os.path.join(dd, str(ct+1)+'.jpg'))\n",
    "\n",
    "        \n",
    "# ## creating csv\n",
    "# p0 = os.listdir(os.path.join(img_dir, all_folders[0]))\n",
    "# p0 = [os.path.join(os.path.join(img_dir, all_folders[0]), im) for im in p0]\n",
    "# df_tra = pd.DataFrame({'image':p0[:-10], 'label':0})\n",
    "# df_val = pd.DataFrame({'image':p0[-10:], 'label':0})\n",
    "# for idx in range(1, len(all_folders)):\n",
    "#     pp = all_folders[idx]\n",
    "#     dd = os.path.join(img_dir, pp)\n",
    "#     intm = os.listdir(dd)\n",
    "#     ii = [os.path.join(dd, im) for im in intm]\n",
    "#     #ppp = all_folders[idx+1]\n",
    "#     #ddd = os.path.join(img_dir, ppp)\n",
    "#     dft = pd.DataFrame({'image':ii[:-10], 'label':idx})\n",
    "#     dfv = pd.DataFrame({'image':ii[-10:], 'label':idx})\n",
    "#     #df2 = pd.DataFrame({'image':os.listdir(ddd), 'class':idx+1})\n",
    "#     df_tra = pd.concat([df_tra, dft], ignore_index = True)\n",
    "#     df_val = pd.concat([df_val, dfv], ignore_index = True)\n",
    "\n",
    "# df_tra.to_csv('train.csv')\n",
    "# df_val.to_csv('val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_transform = transforms.Compose([transforms.Resize((178, 178)),\n",
    "                                       transforms.CenterCrop((128, 128)),\n",
    "                                       #transforms.Grayscale(),                                       \n",
    "                                       #transforms.Lambda(lambda x: x/255.),\n",
    "                                       transforms.ToTensor()])\n",
    "image_datasets=datasets.ImageFolder(r'./downloads500/', custom_transform)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(image_datasets, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "# for idx, (x,y) in enumerate(loader):\n",
    "#     print(idx, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a Custom DataLoader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\curti\\anaconda3\\lib\\site-packages\\PIL\\Image.py:2966: UserWarning: image file could not be identified because WEBP support not installed\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting ./downloads\\0pine\\110.nearly-natural-artificial-trees-5694-rd-64_600.jpg.webp\n",
      "deleting ./downloads\\0pine\\13.scotchpinetree__44838-200x200__17373__77155.1513076159.jpg.webp\n",
      "deleting ./downloads\\0pine\\153.word-image-2.jpeg.webp\n",
      "deleting ./downloads\\0pine\\16.korean_pine__60240-400x400__54314__60590.1512125788.jpg.webp\n",
      "deleting ./downloads\\0pine\\160.01_europe_oldest_tree_img_20160727_131319.jpg.webp\n",
      "deleting ./downloads\\0pine\\188.009259607039.jpg.webp\n",
      "deleting ./downloads\\0pine\\216.23__09205__83989.1512125387.jpg.webp\n",
      "deleting ./downloads\\0pine\\220.packpine05screenshot-1920x1080-26db2cf24a4e4cffbc58c3d628bb342c.jpg.webp\n",
      "deleting ./downloads\\0pine\\268.01_italus3.jpg.webp\n",
      "deleting ./downloads\\0pine\\350.coulter-pine-with-cones_bryant-baker-1024x683-1.jpg.webp\n",
      "deleting ./downloads\\0pine\\364.evergreen-nursery-shade-trees-pinschaqt-64_400.jpg.webp\n",
      "deleting ./downloads\\0pine\\396.20180910-dsc09970__37335.1574709175.jpg.webp\n",
      "deleting ./downloads\\0pine\\52.packpine01screenshot-1920x1080-d37b75adfc4828d8dd78f21dae5002d3.jpg.webp\n",
      "deleting ./downloads\\0pine\\69.15423_2.jpg.webp\n",
      "deleting ./downloads\\1oak\\220.scarlet__91995.1597182972.jpg.webp\n",
      "deleting ./downloads\\1oak\\241.northernredoaktree-400x400__35116__62789.1512124914.jpg.webp\n",
      "deleting ./downloads\\1oak\\349.015415352200.jpg.webp\n",
      "deleting ./downloads\\1oak\\65.silumuqklzlhrhz6kwd5aqpovi.png.webp\n",
      "deleting ./downloads\\1oak\\76.scarlett__62874.1597280613.jpg.webp\n",
      "deleting ./downloads\\2rose\\164.pl2000023877.jpg.webp\n",
      "deleting ./downloads\\2rose\\218.pl0000077994_card2_lg.jpg.webp\n",
      "deleting ./downloads\\2rose\\225.1576922178534_0..jpg.webp\n",
      "deleting ./downloads\\2rose\\289.rainbow-colour-rose-flowers-handmade-silk-satin-rose-flowers-wedding-bridal-bouquet-home-decoration-wedding-flowers.jpg.webp\n",
      "deleting ./downloads\\2rose\\307.platinum_black_diamond_engagement_ring_rose_flower_wedding_ring_1.50_carat_floral_anniversary_ring_vintage_unique_handmade_certified2__94646.1571426008.jpg.webp\n",
      "deleting ./downloads\\2rose\\324.red-fabric-artificial-rose-flower-bunches-by-fourwalls-red-fabric-artificial-rose-flower-bunches-by--el1g2x.jpg.webp\n",
      "deleting ./downloads\\2rose\\38.0372-10_20red__52655__60361.1542008179.jpg.webp\n",
      "deleting ./downloads\\2rose\\41.redcakeflowers__21534.1503954008.jpg.webp\n",
      "deleting ./downloads\\2rose\\80.artificial-red-rose-flower-wedding-bridal-bouquet-valentine-s-day-or-birthday-propose-party-magic-trick.jpg.webp\n",
      "deleting ./downloads\\3daisy\\106.scan_1_copy__69523.1530683301.jpg.webp\n",
      "deleting ./downloads\\3daisy\\120.english-daisy-double-mixed-colors-flower-perennial-ferry-morse_800x.jpg.webp\n",
      "deleting ./downloads\\3daisy\\151.vigoro-perennials-2091-64_400.jpg.webp\n",
      "deleting ./downloads\\3daisy\\168.crazy-daisy-3.jpg.webp\n",
      "deleting ./downloads\\3daisy\\169.close_up_daisy_ala_3397447d.jpg.webp\n",
      "deleting ./downloads\\3daisy\\24.cape_town_blue_blue_felicia_daisy_flowers_and_foliage__98270.1611348788.jpg.webp\n",
      "deleting ./downloads\\3daisy\\311.sku4133607.jpg.webp\n",
      "deleting ./downloads\\3daisy\\348.764677763230.jpg.webp\n",
      "deleting ./downloads\\3daisy\\355.yellow___64836.1523352694.jpg.webp\n",
      "deleting ./downloads\\3daisy\\375.perennials-90518-64_400.jpg.webp\n",
      "deleting ./downloads\\3daisy\\43.chrysantanum_prf__20318.1530683195.jpg.webp\n",
      "deleting ./downloads\\3daisy\\69.041530303407.jpg.webp\n",
      "deleting ./downloads\\4robin\\118.american-robin_thumb.jpg.webp\n",
      "deleting ./downloads\\4robin\\380.american-robin.jpg.webp\n",
      "deleting ./downloads\\5canary\\101.gloster_canaries_for_sale__pet_birds_for_sell_-_buy_birds_online_-_thefinchfarm.com__18037.1469890702.1280.1280__99540.1565821320.jpg.webp\n",
      "deleting ./downloads\\5canary\\137.white_crested_canary__23608.1569965268.jpg.webp\n",
      "deleting ./downloads\\5canary\\207.green_canary_for_sale_at_the_finch_farm_www.thefinchfarm.com__22281.1461550232.1280.1280__52516.1468897345.1280.1280_copy__54113.1564510934.jpg.webp\n",
      "deleting ./downloads\\5canary\\25.white_canary__27203.1570135463.jpg.webp\n",
      "deleting ./downloads\\5canary\\267.fluffy-canary-bird-wallpaper-orange-canary-609307761.jpg\n",
      "deleting ./downloads\\5canary\\276.zinnia_canary_bird_seeds_zinnia_elegans__20327.1566089072.jpg.webp\n",
      "deleting ./downloads\\5canary\\41.black-headed_canary__24059.1570212736.jpg.webp\n",
      "deleting ./downloads\\5canary\\58.shutterstock_775421128.jpg.webp\n",
      "deleting ./downloads\\5canary\\69.red_agate_canary__60573.1564201861.jpg.webp\n",
      "deleting ./downloads\\5canary\\7.yellow_canary__23894.1447512404.500.659__31405.1565733433.jpg.webp\n",
      "deleting ./downloads\\6sunfish\\1.ocean-sunfish_thumb.jpg.webp\n",
      "deleting ./downloads\\6sunfish\\21.01-sunfish-new-zealand-hoodwinker.jpg.webp\n",
      "deleting ./downloads\\6sunfish\\224.russia-sakhalin-sunfish-1-tonne-fish-647_091517071327.jpg.webp\n",
      "deleting ./downloads\\6sunfish\\25.mola-tecta-or-hoodwinker-sunfish-in-port-hardy-b-c.jpg.webp\n",
      "deleting ./downloads\\6sunfish\\263.uersssz77jfzthwrn3fhbjwimy.jpg.webp\n",
      "deleting ./downloads\\6sunfish\\275.poh4ia2ggzosbdditstw7sb2bu.jpg.webp\n",
      "deleting ./downloads\\6sunfish\\327.5346b560d62478b7ca07b836e94dfba9.webp\n",
      "deleting ./downloads\\6sunfish\\86.sdljl-sunfish-mola-mola-2014oct21.webp\n",
      "deleting ./downloads\\7salmon\\183.sockeye-salmon_02.jpg.webp\n"
     ]
    }
   ],
   "source": [
    "class SemCogData(Dataset):\n",
    "\n",
    "    def __init__(self, csv_path,transform=None):\n",
    "    \n",
    "        df = pd.read_csv(csv_path, index_col=0)\n",
    "        self.csv_path = csv_path\n",
    "        self.img_names = df.image.values\n",
    "        self.y = df['label'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         img = Image.open(self.img_names[index])\n",
    "\n",
    "#         if self.transform is not None:\n",
    "#             img = self.transform(img)\n",
    "\n",
    "#         label = self.y[index]\n",
    "#         return img, label\n",
    "        try:\n",
    "            img = Image.open(self.img_names[index])\n",
    "\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "\n",
    "            label = self.y[index]\n",
    "            return img, label\n",
    "        except:\n",
    "            print('deleting', self.img_names[index])\n",
    "            os.remove(self.img_names[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "p0 = os.listdir(os.path.join(img_dir, all_folders[0]))\n",
    "p0 = [os.path.join(os.path.join(img_dir, all_folders[0]), im) for im in p0]\n",
    "df_tra = pd.DataFrame({'image':p0[:-10], 'label':0})\n",
    "df_val = pd.DataFrame({'image':p0[-10:], 'label':0})\n",
    "for idx in range(1, len(all_folders)):\n",
    "    pp = all_folders[idx]\n",
    "    dd = os.path.join(img_dir, pp)\n",
    "    intm = os.listdir(dd)\n",
    "    ii = [os.path.join(dd, im) for im in intm]\n",
    "    #ppp = all_folders[idx+1]\n",
    "    #ddd = os.path.join(img_dir, ppp)\n",
    "    dft = pd.DataFrame({'image':ii[:-10], 'label':idx})\n",
    "    dfv = pd.DataFrame({'image':ii[-10:], 'label':idx})\n",
    "    #df2 = pd.DataFrame({'image':os.listdir(ddd), 'class':idx+1})\n",
    "    df_tra = pd.concat([df_tra, dft], ignore_index = True)\n",
    "    df_val = pd.concat([df_val, dfv], ignore_index = True)\n",
    "\n",
    "df_tra.to_csv('train.csv')\n",
    "df_val.to_csv('val.csv')\n",
    "# Note that transforms.ToTensor()\n",
    "# already divides pixels by 255. internally\n",
    "\n",
    "custom_transform = transforms.Compose([transforms.CenterCrop((178, 178)),\n",
    "                                       transforms.Resize((128, 128)),\n",
    "                                       #transforms.Grayscale(),                                       \n",
    "                                       #transforms.Lambda(lambda x: x/255.),\n",
    "                                       transforms.ToTensor()])\n",
    "\n",
    "train_dataset = SemCogData(csv_path='train.csv',\n",
    "                              transform=custom_transform)\n",
    "\n",
    "valid_dataset = SemCogData(csv_path='val.csv',\n",
    "                              transform=custom_transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4, drop_last=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4, drop_last=True)\n",
    "for idx in range(len(train_dataset)):\n",
    "    a = train_dataset[idx]\n",
    "    \n",
    "for idx in range(len(valid_dataset)):\n",
    "    a = valid_dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch index: 0 | Batch size: 32\n",
      "Epoch: 2 | Batch index: 0 | Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "for epoch in range(2):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        time.sleep(1)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quadro RTX 8000'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6hghKPxj5w0"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell that implements the ResNet-34 architecture is a derivative of the code provided at https://pytorch.org/docs/0.4.0/_modules/torchvision/models/resnet.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, grayscale):\n",
    "        self.inplanes = 64\n",
    "        if grayscale:\n",
    "            in_dim = 1\n",
    "        else:\n",
    "            in_dim = 3\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1, padding=2)\n",
    "        self.fc = nn.Linear(2048 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n)**.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "\n",
    "\n",
    "\n",
    "def resnet101(num_classes, grayscale):\n",
    "    \"\"\"Constructs a ResNet-101 model.\"\"\"\n",
    "    model = ResNet(block=Bottleneck, \n",
    "                   layers=[3, 4, 23, 3],\n",
    "                   num_classes=NUM_CLASSES,\n",
    "                   grayscale=grayscale)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_lza9t_uj5w1"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "##########################\n",
    "### COST AND OPTIMIZER\n",
    "##########################\n",
    "\n",
    "model = resnet101(NUM_CLASSES, GRAYSCALE)\n",
    "model.to(DEVICE)\n",
    "\n",
    "cost_fn = torch.nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAodboScj5w6"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2384585,
     "status": "ok",
     "timestamp": 1524976888520,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "Dzh3ROmRj5w7",
    "outputId": "5f8fd8c9-b076-403a-b0b7-fd2d498b48d7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/050 | Batch 0000/0097 | Cost: 2.0943\n",
      "Epoch: 001/050 | Batch 0050/0097 | Cost: 1.5921\n",
      "Epoch: 001/050 | Train: 29.501%\n",
      "Time elapsed: 2.13 min\n",
      "Epoch: 002/050 | Batch 0000/0097 | Cost: 1.6443\n",
      "Epoch: 002/050 | Batch 0050/0097 | Cost: 1.8785\n",
      "Epoch: 002/050 | Train: 42.293%\n",
      "Time elapsed: 3.58 min\n",
      "Epoch: 003/050 | Batch 0000/0097 | Cost: 1.4199\n",
      "Epoch: 003/050 | Batch 0050/0097 | Cost: 1.0640\n",
      "Epoch: 003/050 | Train: 49.385%\n",
      "Time elapsed: 5.02 min\n",
      "Epoch: 004/050 | Batch 0000/0097 | Cost: 1.2543\n",
      "Epoch: 004/050 | Batch 0050/0097 | Cost: 1.4648\n",
      "Epoch: 004/050 | Train: 50.486%\n",
      "Time elapsed: 6.39 min\n",
      "Epoch: 005/050 | Batch 0000/0097 | Cost: 1.5777\n",
      "Epoch: 005/050 | Batch 0050/0097 | Cost: 1.5948\n",
      "Epoch: 005/050 | Train: 56.218%\n",
      "Time elapsed: 7.77 min\n",
      "Epoch: 006/050 | Batch 0000/0097 | Cost: 1.6418\n",
      "Epoch: 006/050 | Batch 0050/0097 | Cost: 0.8949\n",
      "Epoch: 006/050 | Train: 50.939%\n",
      "Time elapsed: 9.16 min\n",
      "Epoch: 007/050 | Batch 0000/0097 | Cost: 1.4508\n",
      "Epoch: 007/050 | Batch 0050/0097 | Cost: 1.2232\n",
      "Epoch: 007/050 | Train: 60.978%\n",
      "Time elapsed: 10.55 min\n",
      "Epoch: 008/050 | Batch 0000/0097 | Cost: 0.8133\n",
      "Epoch: 008/050 | Batch 0050/0097 | Cost: 1.2143\n",
      "Epoch: 008/050 | Train: 67.260%\n",
      "Time elapsed: 11.95 min\n",
      "Epoch: 009/050 | Batch 0000/0097 | Cost: 0.6797\n",
      "Epoch: 009/050 | Batch 0050/0097 | Cost: 1.0147\n",
      "Epoch: 009/050 | Train: 63.277%\n",
      "Time elapsed: 13.31 min\n",
      "Epoch: 010/050 | Batch 0000/0097 | Cost: 0.7874\n",
      "Epoch: 010/050 | Batch 0050/0097 | Cost: 1.2333\n",
      "Epoch: 010/050 | Train: 65.058%\n",
      "Time elapsed: 14.69 min\n",
      "Epoch: 011/050 | Batch 0000/0097 | Cost: 1.1751\n",
      "Epoch: 011/050 | Batch 0050/0097 | Cost: 1.0424\n",
      "Epoch: 011/050 | Train: 65.965%\n",
      "Time elapsed: 16.05 min\n",
      "Epoch: 012/050 | Batch 0000/0097 | Cost: 0.5848\n",
      "Epoch: 012/050 | Batch 0050/0097 | Cost: 0.9291\n",
      "Epoch: 012/050 | Train: 71.017%\n",
      "Time elapsed: 17.47 min\n",
      "Epoch: 013/050 | Batch 0000/0097 | Cost: 1.0432\n",
      "Epoch: 013/050 | Batch 0050/0097 | Cost: 1.1419\n",
      "Epoch: 013/050 | Train: 73.348%\n",
      "Time elapsed: 18.84 min\n",
      "Epoch: 014/050 | Batch 0000/0097 | Cost: 0.9858\n",
      "Epoch: 014/050 | Batch 0050/0097 | Cost: 0.8245\n",
      "Epoch: 014/050 | Train: 74.288%\n",
      "Time elapsed: 20.24 min\n",
      "Epoch: 015/050 | Batch 0000/0097 | Cost: 0.8589\n",
      "Epoch: 015/050 | Batch 0050/0097 | Cost: 0.9800\n",
      "Epoch: 015/050 | Train: 71.179%\n",
      "Time elapsed: 21.61 min\n",
      "Epoch: 016/050 | Batch 0000/0097 | Cost: 0.7836\n",
      "Epoch: 016/050 | Batch 0050/0097 | Cost: 1.2590\n",
      "Epoch: 016/050 | Train: 73.705%\n",
      "Time elapsed: 23.01 min\n",
      "Epoch: 017/050 | Batch 0000/0097 | Cost: 0.6754\n",
      "Epoch: 017/050 | Batch 0050/0097 | Cost: 0.9847\n",
      "Epoch: 017/050 | Train: 76.975%\n",
      "Time elapsed: 24.37 min\n",
      "Epoch: 018/050 | Batch 0000/0097 | Cost: 0.5874\n",
      "Epoch: 018/050 | Batch 0050/0097 | Cost: 0.7888\n",
      "Epoch: 018/050 | Train: 75.324%\n",
      "Time elapsed: 25.79 min\n",
      "Epoch: 019/050 | Batch 0000/0097 | Cost: 0.6569\n",
      "Epoch: 019/050 | Batch 0050/0097 | Cost: 0.9769\n",
      "Epoch: 019/050 | Train: 81.930%\n",
      "Time elapsed: 27.17 min\n",
      "Epoch: 020/050 | Batch 0000/0097 | Cost: 0.4447\n",
      "Epoch: 020/050 | Batch 0050/0097 | Cost: 0.9244\n",
      "Epoch: 020/050 | Train: 71.632%\n",
      "Time elapsed: 28.56 min\n",
      "Epoch: 021/050 | Batch 0000/0097 | Cost: 0.4962\n",
      "Epoch: 021/050 | Batch 0050/0097 | Cost: 0.6309\n",
      "Epoch: 021/050 | Train: 75.453%\n",
      "Time elapsed: 29.92 min\n",
      "Epoch: 022/050 | Batch 0000/0097 | Cost: 0.4558\n",
      "Epoch: 022/050 | Batch 0050/0097 | Cost: 0.3420\n",
      "Epoch: 022/050 | Train: 80.538%\n",
      "Time elapsed: 31.28 min\n",
      "Epoch: 023/050 | Batch 0000/0097 | Cost: 0.2921\n",
      "Epoch: 023/050 | Batch 0050/0097 | Cost: 0.4754\n",
      "Epoch: 023/050 | Train: 80.084%\n",
      "Time elapsed: 32.65 min\n",
      "Epoch: 024/050 | Batch 0000/0097 | Cost: 0.7077\n",
      "Epoch: 024/050 | Batch 0050/0097 | Cost: 0.6384\n",
      "Epoch: 024/050 | Train: 83.323%\n",
      "Time elapsed: 34.03 min\n",
      "Epoch: 025/050 | Batch 0000/0097 | Cost: 0.3305\n",
      "Epoch: 025/050 | Batch 0050/0097 | Cost: 0.4123\n",
      "Epoch: 025/050 | Train: 83.646%\n",
      "Time elapsed: 35.40 min\n",
      "Epoch: 026/050 | Batch 0000/0097 | Cost: 0.5433\n",
      "Epoch: 026/050 | Batch 0050/0097 | Cost: 0.3955\n",
      "Epoch: 026/050 | Train: 87.889%\n",
      "Time elapsed: 36.78 min\n",
      "Epoch: 027/050 | Batch 0000/0097 | Cost: 0.3313\n",
      "Epoch: 027/050 | Batch 0050/0097 | Cost: 0.4026\n",
      "Epoch: 027/050 | Train: 80.764%\n",
      "Time elapsed: 38.26 min\n",
      "Epoch: 028/050 | Batch 0000/0097 | Cost: 0.3260\n",
      "Epoch: 028/050 | Batch 0050/0097 | Cost: 0.1131\n",
      "Epoch: 028/050 | Train: 89.152%\n",
      "Time elapsed: 39.65 min\n",
      "Epoch: 029/050 | Batch 0000/0097 | Cost: 0.3066\n",
      "Epoch: 029/050 | Batch 0050/0097 | Cost: 0.3443\n",
      "Epoch: 029/050 | Train: 89.896%\n",
      "Time elapsed: 41.02 min\n",
      "Epoch: 030/050 | Batch 0000/0097 | Cost: 0.3112\n",
      "Epoch: 030/050 | Batch 0050/0097 | Cost: 0.4281\n",
      "Epoch: 030/050 | Train: 89.281%\n",
      "Time elapsed: 42.41 min\n",
      "Epoch: 031/050 | Batch 0000/0097 | Cost: 0.2387\n",
      "Epoch: 031/050 | Batch 0050/0097 | Cost: 0.4725\n",
      "Epoch: 031/050 | Train: 94.981%\n",
      "Time elapsed: 43.78 min\n",
      "Epoch: 032/050 | Batch 0000/0097 | Cost: 0.1493\n",
      "Epoch: 032/050 | Batch 0050/0097 | Cost: 0.4569\n",
      "Epoch: 032/050 | Train: 93.556%\n",
      "Time elapsed: 45.13 min\n",
      "Epoch: 033/050 | Batch 0000/0097 | Cost: 0.0643\n",
      "Epoch: 033/050 | Batch 0050/0097 | Cost: 0.1536\n",
      "Epoch: 033/050 | Train: 90.609%\n",
      "Time elapsed: 46.55 min\n",
      "Epoch: 034/050 | Batch 0000/0097 | Cost: 0.0653\n",
      "Epoch: 034/050 | Batch 0050/0097 | Cost: 0.6523\n",
      "Epoch: 034/050 | Train: 96.665%\n",
      "Time elapsed: 47.92 min\n",
      "Epoch: 035/050 | Batch 0000/0097 | Cost: 0.0920\n",
      "Epoch: 035/050 | Batch 0050/0097 | Cost: 0.1108\n",
      "Epoch: 035/050 | Train: 93.459%\n",
      "Time elapsed: 49.29 min\n",
      "Epoch: 036/050 | Batch 0000/0097 | Cost: 0.0611\n",
      "Epoch: 036/050 | Batch 0050/0097 | Cost: 0.0972\n",
      "Epoch: 036/050 | Train: 96.600%\n",
      "Time elapsed: 50.66 min\n",
      "Epoch: 037/050 | Batch 0000/0097 | Cost: 0.0683\n",
      "Epoch: 037/050 | Batch 0050/0097 | Cost: 0.0395\n",
      "Epoch: 037/050 | Train: 98.672%\n",
      "Time elapsed: 52.05 min\n",
      "Epoch: 038/050 | Batch 0000/0097 | Cost: 0.2063\n",
      "Epoch: 038/050 | Batch 0050/0097 | Cost: 0.2231\n",
      "Epoch: 038/050 | Train: 91.807%\n",
      "Time elapsed: 53.45 min\n",
      "Epoch: 039/050 | Batch 0000/0097 | Cost: 0.0396\n",
      "Epoch: 039/050 | Batch 0050/0097 | Cost: 0.0317\n",
      "Epoch: 039/050 | Train: 96.665%\n",
      "Time elapsed: 54.84 min\n",
      "Epoch: 040/050 | Batch 0000/0097 | Cost: 0.3368\n",
      "Epoch: 040/050 | Batch 0050/0097 | Cost: 0.3917\n",
      "Epoch: 040/050 | Train: 98.187%\n",
      "Time elapsed: 56.24 min\n",
      "Epoch: 041/050 | Batch 0000/0097 | Cost: 0.1472\n",
      "Epoch: 041/050 | Batch 0050/0097 | Cost: 0.0441\n",
      "Epoch: 041/050 | Train: 93.329%\n",
      "Time elapsed: 57.63 min\n",
      "Epoch: 042/050 | Batch 0000/0097 | Cost: 0.0105\n",
      "Epoch: 042/050 | Batch 0050/0097 | Cost: 0.0913\n",
      "Epoch: 042/050 | Train: 96.341%\n",
      "Time elapsed: 59.07 min\n",
      "Epoch: 043/050 | Batch 0000/0097 | Cost: 0.1563\n",
      "Epoch: 043/050 | Batch 0050/0097 | Cost: 0.0204\n",
      "Epoch: 043/050 | Train: 98.575%\n",
      "Time elapsed: 60.48 min\n",
      "Epoch: 044/050 | Batch 0000/0097 | Cost: 0.0115\n",
      "Epoch: 044/050 | Batch 0050/0097 | Cost: 0.0139\n",
      "Epoch: 044/050 | Train: 98.316%\n",
      "Time elapsed: 61.88 min\n",
      "Epoch: 045/050 | Batch 0000/0097 | Cost: 0.0535\n",
      "Epoch: 045/050 | Batch 0050/0097 | Cost: 0.0435\n",
      "Epoch: 045/050 | Train: 98.510%\n",
      "Time elapsed: 63.32 min\n",
      "Epoch: 046/050 | Batch 0000/0097 | Cost: 0.1024\n",
      "Epoch: 046/050 | Batch 0050/0097 | Cost: 0.0439\n",
      "Epoch: 046/050 | Train: 96.762%\n",
      "Time elapsed: 64.73 min\n",
      "Epoch: 047/050 | Batch 0000/0097 | Cost: 0.0064\n",
      "Epoch: 047/050 | Batch 0050/0097 | Cost: 0.0088\n",
      "Epoch: 047/050 | Train: 99.126%\n",
      "Time elapsed: 66.16 min\n",
      "Epoch: 048/050 | Batch 0000/0097 | Cost: 0.0070\n",
      "Epoch: 048/050 | Batch 0050/0097 | Cost: 0.0574\n",
      "Epoch: 048/050 | Train: 96.308%\n",
      "Time elapsed: 67.55 min\n",
      "Epoch: 049/050 | Batch 0000/0097 | Cost: 0.0077\n",
      "Epoch: 049/050 | Batch 0050/0097 | Cost: 0.1254\n",
      "Epoch: 049/050 | Train: 98.381%\n",
      "Time elapsed: 68.98 min\n",
      "Epoch: 050/050 | Batch 0000/0097 | Cost: 0.1113\n",
      "Epoch: 050/050 | Batch 0050/0097 | Cost: 0.0973\n",
      "Epoch: 050/050 | Train: 94.203%\n",
      "Time elapsed: 70.38 min\n",
      "Total Training Time: 70.38 min\n"
     ]
    }
   ],
   "source": [
    "train_loader = loader\n",
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = cost_fn(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%%' % (\n",
    "              epoch+1, NUM_EPOCHS, \n",
    "              compute_accuracy(model, train_loader, device=DEVICE)))\n",
    "              #,| Valid: %.3f%% compute_accuracy(model, valid_loader, device=DEVICE)))\n",
    "        \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'resnet_epoch50.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = ResNet(block=Bottleneck, \n",
    "               layers=[3, 4, 23, 3],\n",
    "               num_classes=NUM_CLASSES,\n",
    "               grayscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_state_dict(torch.load('resnet_epoch50.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(94.2034, device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.to(DEVICE)\n",
    "model2.eval()\n",
    "compute_accuracy(model2, train_loader, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "paaeEQHQj5xC"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6514,
     "status": "ok",
     "timestamp": 1524976895054,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "gzQMWKq5j5xE",
    "outputId": "de7dc005-5eeb-4177-9f9f-d9b5d1358db9"
   },
   "outputs": [],
   "source": [
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (features, targets) in enumerate(loader):\n",
    "\n",
    "    features = features\n",
    "    targets = targets\n",
    "    break\n",
    "    \n",
    "plt.imshow(np.transpose(features[0], (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.transpose(features[5], (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "logits, probas = model(features.to(DEVICE)[0, None])\n",
    "print('Probability Female %.2f%%' % (probas[0][0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark -iv"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "convnet-vgg16.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
