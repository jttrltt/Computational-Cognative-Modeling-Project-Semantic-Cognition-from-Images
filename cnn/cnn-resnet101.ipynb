{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkoGLH_Tj5wn"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ORj09gnrj5wp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23936,
     "status": "ok",
     "timestamp": 1524974497505,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "NnT0sZIwj5wu",
    "outputId": "55aed925-d17e-4c6a-8c71-0d9b3bde5637"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Architecture\n",
    "NUM_FEATURES = 128*128\n",
    "NUM_CLASSES = 8\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = 'cuda' # default GPU device\n",
    "GRAYSCALE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = './downloads'\n",
    "all_folders = os.listdir(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## renaming images\n",
    "\n",
    "# ct = 0\n",
    "# for ii in all_folders:\n",
    "#     dd = os.path.join(img_dir, ii)\n",
    "#     allimg = os.listdir(dd)\n",
    "#     for idx, filename in enumerate(allimg):\n",
    "#         os.rename(os.path.join(dd,filename), os.path.join(dd, str(ct+1)+'.jpg'))\n",
    "\n",
    "        \n",
    "# ## creating csv\n",
    "# p0 = os.listdir(os.path.join(img_dir, all_folders[0]))\n",
    "# p0 = [os.path.join(os.path.join(img_dir, all_folders[0]), im) for im in p0]\n",
    "# df_tra = pd.DataFrame({'image':p0[:-10], 'label':0})\n",
    "# df_val = pd.DataFrame({'image':p0[-10:], 'label':0})\n",
    "# for idx in range(1, len(all_folders)):\n",
    "#     pp = all_folders[idx]\n",
    "#     dd = os.path.join(img_dir, pp)\n",
    "#     intm = os.listdir(dd)\n",
    "#     ii = [os.path.join(dd, im) for im in intm]\n",
    "#     #ppp = all_folders[idx+1]\n",
    "#     #ddd = os.path.join(img_dir, ppp)\n",
    "#     dft = pd.DataFrame({'image':ii[:-10], 'label':idx})\n",
    "#     dfv = pd.DataFrame({'image':ii[-10:], 'label':idx})\n",
    "#     #df2 = pd.DataFrame({'image':os.listdir(ddd), 'class':idx+1})\n",
    "#     df_tra = pd.concat([df_tra, dft], ignore_index = True)\n",
    "#     df_val = pd.concat([df_val, dfv], ignore_index = True)\n",
    "\n",
    "# df_tra.to_csv('train.csv')\n",
    "# df_val.to_csv('val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_transform = transforms.Compose([transforms.Resize((178, 178)),\n",
    "                                       transforms.CenterCrop((128, 128)),\n",
    "                                       #transforms.Grayscale(),                                       \n",
    "                                       #transforms.Lambda(lambda x: x/255.),\n",
    "                                       transforms.ToTensor()])\n",
    "image_datasets=datasets.ImageFolder(r'C:\\Users\\curti\\Desktop\\1016-Project\\cnn\\downloads', custom_transform)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(image_datasets, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "# for idx, (x,y) in enumerate(loader):\n",
    "#     print(idx, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a Custom DataLoader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\curti\\anaconda3\\lib\\site-packages\\PIL\\Image.py:2966: UserWarning: image file could not be identified because WEBP support not installed\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting ./downloads\\0pine\\110.nearly-natural-artificial-trees-5694-rd-64_600.jpg.webp\n",
      "deleting ./downloads\\0pine\\13.scotchpinetree__44838-200x200__17373__77155.1513076159.jpg.webp\n",
      "deleting ./downloads\\0pine\\153.word-image-2.jpeg.webp\n",
      "deleting ./downloads\\0pine\\16.korean_pine__60240-400x400__54314__60590.1512125788.jpg.webp\n",
      "deleting ./downloads\\0pine\\160.01_europe_oldest_tree_img_20160727_131319.jpg.webp\n",
      "deleting ./downloads\\0pine\\188.009259607039.jpg.webp\n",
      "deleting ./downloads\\0pine\\216.23__09205__83989.1512125387.jpg.webp\n",
      "deleting ./downloads\\0pine\\220.packpine05screenshot-1920x1080-26db2cf24a4e4cffbc58c3d628bb342c.jpg.webp\n",
      "deleting ./downloads\\0pine\\268.01_italus3.jpg.webp\n",
      "deleting ./downloads\\0pine\\350.coulter-pine-with-cones_bryant-baker-1024x683-1.jpg.webp\n",
      "deleting ./downloads\\0pine\\364.evergreen-nursery-shade-trees-pinschaqt-64_400.jpg.webp\n",
      "deleting ./downloads\\0pine\\396.20180910-dsc09970__37335.1574709175.jpg.webp\n",
      "deleting ./downloads\\0pine\\52.packpine01screenshot-1920x1080-d37b75adfc4828d8dd78f21dae5002d3.jpg.webp\n",
      "deleting ./downloads\\0pine\\69.15423_2.jpg.webp\n",
      "deleting ./downloads\\1oak\\220.scarlet__91995.1597182972.jpg.webp\n",
      "deleting ./downloads\\1oak\\241.northernredoaktree-400x400__35116__62789.1512124914.jpg.webp\n",
      "deleting ./downloads\\1oak\\349.015415352200.jpg.webp\n",
      "deleting ./downloads\\1oak\\65.silumuqklzlhrhz6kwd5aqpovi.png.webp\n",
      "deleting ./downloads\\1oak\\76.scarlett__62874.1597280613.jpg.webp\n",
      "deleting ./downloads\\2rose\\164.pl2000023877.jpg.webp\n",
      "deleting ./downloads\\2rose\\218.pl0000077994_card2_lg.jpg.webp\n",
      "deleting ./downloads\\2rose\\225.1576922178534_0..jpg.webp\n",
      "deleting ./downloads\\2rose\\289.rainbow-colour-rose-flowers-handmade-silk-satin-rose-flowers-wedding-bridal-bouquet-home-decoration-wedding-flowers.jpg.webp\n",
      "deleting ./downloads\\2rose\\307.platinum_black_diamond_engagement_ring_rose_flower_wedding_ring_1.50_carat_floral_anniversary_ring_vintage_unique_handmade_certified2__94646.1571426008.jpg.webp\n",
      "deleting ./downloads\\2rose\\324.red-fabric-artificial-rose-flower-bunches-by-fourwalls-red-fabric-artificial-rose-flower-bunches-by--el1g2x.jpg.webp\n",
      "deleting ./downloads\\2rose\\38.0372-10_20red__52655__60361.1542008179.jpg.webp\n",
      "deleting ./downloads\\2rose\\41.redcakeflowers__21534.1503954008.jpg.webp\n",
      "deleting ./downloads\\2rose\\80.artificial-red-rose-flower-wedding-bridal-bouquet-valentine-s-day-or-birthday-propose-party-magic-trick.jpg.webp\n",
      "deleting ./downloads\\3daisy\\106.scan_1_copy__69523.1530683301.jpg.webp\n",
      "deleting ./downloads\\3daisy\\120.english-daisy-double-mixed-colors-flower-perennial-ferry-morse_800x.jpg.webp\n",
      "deleting ./downloads\\3daisy\\151.vigoro-perennials-2091-64_400.jpg.webp\n",
      "deleting ./downloads\\3daisy\\168.crazy-daisy-3.jpg.webp\n",
      "deleting ./downloads\\3daisy\\169.close_up_daisy_ala_3397447d.jpg.webp\n",
      "deleting ./downloads\\3daisy\\24.cape_town_blue_blue_felicia_daisy_flowers_and_foliage__98270.1611348788.jpg.webp\n",
      "deleting ./downloads\\3daisy\\311.sku4133607.jpg.webp\n",
      "deleting ./downloads\\3daisy\\348.764677763230.jpg.webp\n",
      "deleting ./downloads\\3daisy\\355.yellow___64836.1523352694.jpg.webp\n",
      "deleting ./downloads\\3daisy\\375.perennials-90518-64_400.jpg.webp\n",
      "deleting ./downloads\\3daisy\\43.chrysantanum_prf__20318.1530683195.jpg.webp\n",
      "deleting ./downloads\\3daisy\\69.041530303407.jpg.webp\n",
      "deleting ./downloads\\4robin\\118.american-robin_thumb.jpg.webp\n",
      "deleting ./downloads\\4robin\\380.american-robin.jpg.webp\n",
      "deleting ./downloads\\5canary\\101.gloster_canaries_for_sale__pet_birds_for_sell_-_buy_birds_online_-_thefinchfarm.com__18037.1469890702.1280.1280__99540.1565821320.jpg.webp\n",
      "deleting ./downloads\\5canary\\137.white_crested_canary__23608.1569965268.jpg.webp\n",
      "deleting ./downloads\\5canary\\207.green_canary_for_sale_at_the_finch_farm_www.thefinchfarm.com__22281.1461550232.1280.1280__52516.1468897345.1280.1280_copy__54113.1564510934.jpg.webp\n",
      "deleting ./downloads\\5canary\\25.white_canary__27203.1570135463.jpg.webp\n",
      "deleting ./downloads\\5canary\\267.fluffy-canary-bird-wallpaper-orange-canary-609307761.jpg\n",
      "deleting ./downloads\\5canary\\276.zinnia_canary_bird_seeds_zinnia_elegans__20327.1566089072.jpg.webp\n",
      "deleting ./downloads\\5canary\\41.black-headed_canary__24059.1570212736.jpg.webp\n",
      "deleting ./downloads\\5canary\\58.shutterstock_775421128.jpg.webp\n",
      "deleting ./downloads\\5canary\\69.red_agate_canary__60573.1564201861.jpg.webp\n",
      "deleting ./downloads\\5canary\\7.yellow_canary__23894.1447512404.500.659__31405.1565733433.jpg.webp\n",
      "deleting ./downloads\\6sunfish\\1.ocean-sunfish_thumb.jpg.webp\n",
      "deleting ./downloads\\6sunfish\\21.01-sunfish-new-zealand-hoodwinker.jpg.webp\n",
      "deleting ./downloads\\6sunfish\\224.russia-sakhalin-sunfish-1-tonne-fish-647_091517071327.jpg.webp\n",
      "deleting ./downloads\\6sunfish\\25.mola-tecta-or-hoodwinker-sunfish-in-port-hardy-b-c.jpg.webp\n",
      "deleting ./downloads\\6sunfish\\263.uersssz77jfzthwrn3fhbjwimy.jpg.webp\n",
      "deleting ./downloads\\6sunfish\\275.poh4ia2ggzosbdditstw7sb2bu.jpg.webp\n",
      "deleting ./downloads\\6sunfish\\327.5346b560d62478b7ca07b836e94dfba9.webp\n",
      "deleting ./downloads\\6sunfish\\86.sdljl-sunfish-mola-mola-2014oct21.webp\n",
      "deleting ./downloads\\7salmon\\183.sockeye-salmon_02.jpg.webp\n"
     ]
    }
   ],
   "source": [
    "class SemCogData(Dataset):\n",
    "\n",
    "    def __init__(self, csv_path,transform=None):\n",
    "    \n",
    "        df = pd.read_csv(csv_path, index_col=0)\n",
    "        self.csv_path = csv_path\n",
    "        self.img_names = df.image.values\n",
    "        self.y = df['label'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         img = Image.open(self.img_names[index])\n",
    "\n",
    "#         if self.transform is not None:\n",
    "#             img = self.transform(img)\n",
    "\n",
    "#         label = self.y[index]\n",
    "#         return img, label\n",
    "        try:\n",
    "            img = Image.open(self.img_names[index])\n",
    "\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "\n",
    "            label = self.y[index]\n",
    "            return img, label\n",
    "        except:\n",
    "            print('deleting', self.img_names[index])\n",
    "            os.remove(self.img_names[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "p0 = os.listdir(os.path.join(img_dir, all_folders[0]))\n",
    "p0 = [os.path.join(os.path.join(img_dir, all_folders[0]), im) for im in p0]\n",
    "df_tra = pd.DataFrame({'image':p0[:-10], 'label':0})\n",
    "df_val = pd.DataFrame({'image':p0[-10:], 'label':0})\n",
    "for idx in range(1, len(all_folders)):\n",
    "    pp = all_folders[idx]\n",
    "    dd = os.path.join(img_dir, pp)\n",
    "    intm = os.listdir(dd)\n",
    "    ii = [os.path.join(dd, im) for im in intm]\n",
    "    #ppp = all_folders[idx+1]\n",
    "    #ddd = os.path.join(img_dir, ppp)\n",
    "    dft = pd.DataFrame({'image':ii[:-10], 'label':idx})\n",
    "    dfv = pd.DataFrame({'image':ii[-10:], 'label':idx})\n",
    "    #df2 = pd.DataFrame({'image':os.listdir(ddd), 'class':idx+1})\n",
    "    df_tra = pd.concat([df_tra, dft], ignore_index = True)\n",
    "    df_val = pd.concat([df_val, dfv], ignore_index = True)\n",
    "\n",
    "df_tra.to_csv('train.csv')\n",
    "df_val.to_csv('val.csv')\n",
    "# Note that transforms.ToTensor()\n",
    "# already divides pixels by 255. internally\n",
    "\n",
    "custom_transform = transforms.Compose([transforms.CenterCrop((178, 178)),\n",
    "                                       transforms.Resize((128, 128)),\n",
    "                                       #transforms.Grayscale(),                                       \n",
    "                                       #transforms.Lambda(lambda x: x/255.),\n",
    "                                       transforms.ToTensor()])\n",
    "\n",
    "train_dataset = SemCogData(csv_path='train.csv',\n",
    "                              transform=custom_transform)\n",
    "\n",
    "valid_dataset = SemCogData(csv_path='val.csv',\n",
    "                              transform=custom_transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4, drop_last=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4, drop_last=True)\n",
    "for idx in range(len(train_dataset)):\n",
    "    a = train_dataset[idx]\n",
    "    \n",
    "for idx in range(len(valid_dataset)):\n",
    "    a = valid_dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch index: 0 | Batch size: 32\n",
      "Epoch: 2 | Batch index: 0 | Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "for epoch in range(2):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        time.sleep(1)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6hghKPxj5w0"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell that implements the ResNet-34 architecture is a derivative of the code provided at https://pytorch.org/docs/0.4.0/_modules/torchvision/models/resnet.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, grayscale):\n",
    "        self.inplanes = 64\n",
    "        if grayscale:\n",
    "            in_dim = 1\n",
    "        else:\n",
    "            in_dim = 3\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1, padding=2)\n",
    "        self.fc = nn.Linear(2048 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n)**.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "\n",
    "\n",
    "\n",
    "def resnet101(num_classes, grayscale):\n",
    "    \"\"\"Constructs a ResNet-101 model.\"\"\"\n",
    "    model = ResNet(block=Bottleneck, \n",
    "                   layers=[3, 4, 23, 3],\n",
    "                   num_classes=NUM_CLASSES,\n",
    "                   grayscale=grayscale)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_lza9t_uj5w1"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "##########################\n",
    "### COST AND OPTIMIZER\n",
    "##########################\n",
    "\n",
    "model = resnet101(NUM_CLASSES, GRAYSCALE)\n",
    "model.to(DEVICE)\n",
    "\n",
    "cost_fn = torch.nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAodboScj5w6"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2384585,
     "status": "ok",
     "timestamp": 1524976888520,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "Dzh3ROmRj5w7",
    "outputId": "5f8fd8c9-b076-403a-b0b7-fd2d498b48d7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 0000/0097 | Cost: 2.0943\n",
      "Epoch: 001/010 | Batch 0050/0097 | Cost: 1.7822\n",
      "Epoch: 001/010 | Train: 41.386%\n",
      "Time elapsed: 0.80 min\n",
      "Epoch: 002/010 | Batch 0000/0097 | Cost: 1.6077\n",
      "Epoch: 002/010 | Batch 0050/0097 | Cost: 1.8864\n",
      "Epoch: 002/010 | Train: 52.364%\n",
      "Time elapsed: 1.59 min\n",
      "Epoch: 003/010 | Batch 0000/0097 | Cost: 1.2732\n",
      "Epoch: 003/010 | Batch 0050/0097 | Cost: 1.0757\n",
      "Epoch: 003/010 | Train: 39.864%\n",
      "Time elapsed: 2.38 min\n",
      "Epoch: 004/010 | Batch 0000/0097 | Cost: 1.1459\n",
      "Epoch: 004/010 | Batch 0050/0097 | Cost: 1.2331\n",
      "Epoch: 004/010 | Train: 55.861%\n",
      "Time elapsed: 3.14 min\n",
      "Epoch: 005/010 | Batch 0000/0097 | Cost: 1.4254\n",
      "Epoch: 005/010 | Batch 0050/0097 | Cost: 1.3759\n",
      "Epoch: 005/010 | Train: 61.626%\n",
      "Time elapsed: 3.91 min\n",
      "Epoch: 006/010 | Batch 0000/0097 | Cost: 1.4565\n",
      "Epoch: 006/010 | Batch 0050/0097 | Cost: 0.8224\n",
      "Epoch: 006/010 | Train: 56.412%\n",
      "Time elapsed: 4.71 min\n",
      "Epoch: 007/010 | Batch 0000/0097 | Cost: 1.2244\n",
      "Epoch: 007/010 | Batch 0050/0097 | Cost: 1.4984\n",
      "Epoch: 007/010 | Train: 60.168%\n",
      "Time elapsed: 5.50 min\n",
      "Epoch: 008/010 | Batch 0000/0097 | Cost: 0.8064\n",
      "Epoch: 008/010 | Batch 0050/0097 | Cost: 1.2635\n",
      "Epoch: 008/010 | Train: 64.087%\n",
      "Time elapsed: 6.28 min\n",
      "Epoch: 009/010 | Batch 0000/0097 | Cost: 0.6577\n",
      "Epoch: 009/010 | Batch 0050/0097 | Cost: 0.6147\n",
      "Epoch: 009/010 | Train: 69.624%\n",
      "Time elapsed: 7.08 min\n",
      "Epoch: 010/010 | Batch 0000/0097 | Cost: 0.7906\n",
      "Epoch: 010/010 | Batch 0050/0097 | Cost: 1.1704\n",
      "Epoch: 010/010 | Train: 54.145%\n",
      "Time elapsed: 7.88 min\n",
      "Total Training Time: 7.88 min\n"
     ]
    }
   ],
   "source": [
    "train_loader = loader\n",
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = cost_fn(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%%' % (\n",
    "              epoch+1, NUM_EPOCHS, \n",
    "              compute_accuracy(model, train_loader, device=DEVICE)))\n",
    "              #,| Valid: %.3f%% compute_accuracy(model, valid_loader, device=DEVICE)))\n",
    "        \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "paaeEQHQj5xC"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6514,
     "status": "ok",
     "timestamp": 1524976895054,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "gzQMWKq5j5xE",
    "outputId": "de7dc005-5eeb-4177-9f9f-d9b5d1358db9"
   },
   "outputs": [],
   "source": [
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (features, targets) in enumerate(loader):\n",
    "\n",
    "    features = features\n",
    "    targets = targets\n",
    "    break\n",
    "    \n",
    "plt.imshow(np.transpose(features[0], (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.transpose(features[5], (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "logits, probas = model(features.to(DEVICE)[0, None])\n",
    "print('Probability Female %.2f%%' % (probas[0][0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark -iv"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "convnet-vgg16.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
